{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing the libraries\n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import nltk\n",
    "import custom_preprocessor as cp\n",
    "import featurizer as f\n",
    "import plot_learning_curve as plc\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchtext.vocab import  vocab\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau, OneCycleLR, StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import random\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import joblib\n",
    "from collections import Counter\n",
    "from types import SimpleNamespace\n",
    "import wandb\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import  TfidfVectorizer\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33maswin1903\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading the data \n",
    "a=pd.read_excel(\"IntentData2.xlsx\",sheet_name=\"Set 1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "b=pd.read_excel(\"IntentData2.xlsx\",sheet_name=\"Set 2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.concat([a,b],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Original Comment</th>\n",
       "      <th>Positive</th>\n",
       "      <th>Negative (Other)</th>\n",
       "      <th>Not Resolved</th>\n",
       "      <th>Hold</th>\n",
       "      <th>Follow-up, Communication</th>\n",
       "      <th>Knowledge</th>\n",
       "      <th>Effort</th>\n",
       "      <th>Professionalism</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nothing has been resolved. We have been dealin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Nothing has been resolved; dealing with the in...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Very professional and courteous</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Thank you so much for the excellent customer s...</td>\n",
       "      <td>Thank you so much for the excellent customer s...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Impressively fast service. Thank you for corre...</td>\n",
       "      <td>impressively fast service; thank you for corre...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Way too long waiting time!  Insane to wait 1 h...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>way too long waiting time; insane to wait 1 ho...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Original Comment  \\\n",
       "0  Nothing has been resolved. We have been dealin...   \n",
       "1                    Very professional and courteous   \n",
       "2  Thank you so much for the excellent customer s...   \n",
       "3  Impressively fast service. Thank you for corre...   \n",
       "4  Way too long waiting time!  Insane to wait 1 h...   \n",
       "\n",
       "                                            Positive Negative (Other)  \\\n",
       "0                                                NaN              NaN   \n",
       "1                                                NaN              NaN   \n",
       "2  Thank you so much for the excellent customer s...              NaN   \n",
       "3  impressively fast service; thank you for corre...              NaN   \n",
       "4                                                NaN              NaN   \n",
       "\n",
       "                                        Not Resolved  \\\n",
       "0  Nothing has been resolved; dealing with the in...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                                Hold Follow-up, Communication  \\\n",
       "0                                                NaN                      NaN   \n",
       "1                                                NaN                      NaN   \n",
       "2                                                NaN                      NaN   \n",
       "3                                                NaN                      NaN   \n",
       "4  way too long waiting time; insane to wait 1 ho...                      NaN   \n",
       "\n",
       "  Knowledge Effort Professionalism  \n",
       "0       NaN    NaN             NaN  \n",
       "1       NaN    NaN             NaN  \n",
       "2       NaN    NaN             NaN  \n",
       "3       NaN    NaN             NaN  \n",
       "4       NaN    NaN             NaN  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive=df.Positive.unique()\n",
    "cleaned_positive = positive[~pd.isnull(positive)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "negative=df['Negative (Other)'].unique()\n",
    "cleaned_negative = negative[~pd.isnull(negative)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_res=df['Not Resolved'].unique()\n",
    "cleaned_not_res = not_res[~pd.isnull(not_res)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "hold=df['Hold'].unique()\n",
    "cleaned_hold = hold[~pd.isnull(hold)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "follow=df[\"Follow-up, Communication\"].unique()\n",
    "cleaned_follow=follow[~pd.isnull(follow)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "know=df[\"Knowledge\"].unique()\n",
    "cleaned_know=know[~pd.isnull(know)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "effort=df[\"Effort\"].unique()\n",
    "cleaned_effort=effort[~pd.isnull(effort)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prof=df[\"Professionalism\"].unique()\n",
    "cleaned_prof=prof[~pd.isnull(prof)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_mapping = {\n",
    "    'Positive': cleaned_positive, 'Negative (Other)':cleaned_negative, 'Not Resolved':cleaned_not_res,\n",
    "       'Hold':cleaned_hold, 'Follow-up, Communication': cleaned_follow, 'Knowledge':cleaned_know, 'Effort':cleaned_effort,\n",
    "       'Professionalism':cleaned_prof\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 700 entries, 0 to 499\n",
      "Data columns (total 9 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   Original Comment          693 non-null    object\n",
      " 1   Positive                  252 non-null    object\n",
      " 2   Negative (Other)          82 non-null     object\n",
      " 3   Not Resolved              109 non-null    object\n",
      " 4   Hold                      8 non-null      object\n",
      " 5   Follow-up, Communication  87 non-null     object\n",
      " 6   Knowledge                 21 non-null     object\n",
      " 7   Effort                    89 non-null     object\n",
      " 8   Professionalism           30 non-null     object\n",
      "dtypes: object(9)\n",
      "memory usage: 54.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = []\n",
    "\n",
    "# Iterate through rows\n",
    "\n",
    "for index, row in df.iterrows():\n",
    "\n",
    "    non_nan_columns = [column for column in df.columns[1:] if not pd.isna(row[column])]\n",
    "\n",
    "    target.append(non_nan_columns)\n",
    "\n",
    "df['Target'] = target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=df[[\"Original Comment\",\"Target\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "249"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Finding the number of missing targets\n",
    "len(df1[df1['Target'].apply(len) == 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2=df1[df1['Target'].apply(len) != 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Number of records with the target columns:\n",
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Original Comment', 'Positive', 'Negative (Other)', 'Not Resolved',\n",
       "       'Hold', 'Follow-up, Communication', 'Knowledge', 'Effort',\n",
       "       'Professionalism', 'Target'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Github repos\\IntentModelling\\custom_preprocessor.py:40: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
      "  if (bool(BeautifulSoup(text, \"html.parser\").find())==True):\n"
     ]
    }
   ],
   "source": [
    "#Preprocessing the verbatim\n",
    "preprocessor= cp.SpacyPreprocessor(model=\"en_core_web_sm\",lammetize=False, remove_stop=False)\n",
    "cleaned_text= preprocessor.fit_transform(df2['Original Comment'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\aswin\\AppData\\Local\\Temp\\ipykernel_83048\\1542965680.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df2[\"cleaned_text\"]=cleaned_text\n"
     ]
    }
   ],
   "source": [
    "df2[\"cleaned_text\"]=cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the Target Labels\n",
    "target_labels=['Positive', 'Negative (Other)', 'Not Resolved',\n",
    "       'Hold', 'Follow-up, Communication', 'Knowledge', 'Effort',\n",
    "       'Professionalism']\n",
    "\n",
    "# Initialize and fit the MultiLabelBinarizer\n",
    "mlb = MultiLabelBinarizer()\n",
    "encoded_targets = mlb.fit_transform(df2['Target'].apply(lambda x: [label for label in x if label in target_labels]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separating the features and target\n",
    "X=df2[\"cleaned_text\"]\n",
    "y=encoded_targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a train test split\n",
    "X_train,X_test1,y_train,y_test1=train_test_split(X,y,test_size=0.1,random_state=42)\n",
    "X_test, X_valid, y_test, y_valid = train_test_split(X_test1, y_test1, test_size= 0.5, random_state= 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a Custom Dataset \n",
    "class CustomDataset(torch.utils.data.Dataset):\n",
    "\n",
    "    def __init__(self,X,y):\n",
    "        self.X=np.array(X)\n",
    "        self.y=y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return(len(self.X))\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx=idx.tolist()\n",
    "        text=self.X[idx]\n",
    "        labels=self.y[idx]\n",
    "        sample=(text,labels)\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=CustomDataset(X_train,y_train)\n",
    "valid_set=CustomDataset(X_valid,y_valid)\n",
    "test_Set=CustomDataset(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Vectorizing using tfidf vectorizer\n",
    "vectorizer=TfidfVectorizer(stop_words=\"english\",min_df=4,max_features=5000).fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_vec=vectorizer.transform(X_train)\n",
    "X_test_vec=vectorizer.transform(X_test)\n",
    "X_valid_vec=vectorizer.transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Converting to Tensor\n",
    "X_train_tensor=torch.tensor(X_train_vec.toarray()).float()\n",
    "X_valid_tensor=torch.tensor(X_valid_vec.toarray()).float()\n",
    "X_test_tensor=torch.tensor(X_test_vec.toarray()).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_tensor=torch.tensor(np.array(y_train)).long()\n",
    "y_valid_tensor=torch.tensor(np.array(y_valid)).long()\n",
    "y_test_tensor=torch.tensor(np.array(y_test)).long()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a torch dataset\n",
    "train_set =torch.utils.data.TensorDataset(X_train_tensor,y_train_tensor)\n",
    "valid_set=torch.utils.data.TensorDataset(X_valid_tensor,y_valid_tensor)\n",
    "test_set=torch.utils.data.TensorDataset(X_test_tensor,y_test_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating Model\n",
    "\n",
    "class Model(nn.Module):\n",
    "\n",
    "    def __init__(self,input_dim,hidden_dim1,hidden_dim2,output_dim,non_linearity):\n",
    "        self.input_dim=input_dim\n",
    "        self.hidden_dim1=hidden_dim1\n",
    "        self.hidden_dim2=hidden_dim2\n",
    "        self.output_dim=output_dim\n",
    "        self.non_linearity=non_linearity\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        #hidden layer1\n",
    "        self.hidden_layer1=nn.Linear(self.input_dim,self.hidden_dim1)\n",
    "        #hidden layer2\n",
    "        self.hidden_layer2=nn.Linear(self.hidden_dim1,self.hidden_dim2)\n",
    "        #output layer\n",
    "        self.output_layer=nn.Linear(self.hidden_dim2,self.output_dim)\n",
    "\n",
    "    def forward(self,input):\n",
    "        hout1=self.non_linearity(self.hidden_layer1(input))\n",
    "        hout2=self.non_linearity(self.hidden_layer2(hout1))\n",
    "        ypred=self.output_layer(hout2)\n",
    "\n",
    "        return ypred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training model for each epoch \n",
    "def train(train_loader, model,optimizer,loss_function,log_batch,log_interval,grad_clipping,max_norm):\n",
    "\n",
    "    #initializing variable as global \n",
    "    #Count will be updated for every epoch\n",
    "    global example_ct_train\n",
    "    global batch_ct_train\n",
    "\n",
    "    #Training loop \n",
    "    #Initializing the train_loss at the the start of the epoch\n",
    "    running_train_loss=0\n",
    "\n",
    "    #Put model in training mode\n",
    "    model.train()\n",
    "\n",
    "    #Iterate on batches from the dataset using train_loader\n",
    "    for input,targets in train_loader:\n",
    "        # move inputs and outputs to GPUs\n",
    "        input = input.to(device)\n",
    "        targets = targets.to(device)\n",
    "\n",
    "        #Forward pass\n",
    "        output=model(input)\n",
    "        loss=loss_function(output,targets.float())\n",
    "\n",
    "        example_ct_train += len(targets)\n",
    "        batch_ct_train+=1\n",
    "\n",
    "        #set gradients to zero\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        #backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        #Gradient clipping\n",
    "        if grad_clipping:\n",
    "            nn.utils.clip_grad_norm(model.parameters(),max_norm=max_norm,norm_type=2)\n",
    "\n",
    "        #Update the parameters using their gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        running_train_loss += loss.item()\n",
    "\n",
    "        if log_batch:\n",
    "            if((batch_ct_train+1) % log_interval)==0:\n",
    "                wandb.log({f\"Train Batch Loss: \":loss})\n",
    "    \n",
    "    #Calculate the mean train loss for the whole dataset for a particular epoch\n",
    "    train_loss = running_train_loss/len(train_loader)\n",
    "\n",
    "    return train_loss\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(loader,model,optimizer,loss_function,log_batch,log_interval):\n",
    "\n",
    "    #initialize variable as global\n",
    "    # these counts will be updated every epoch\n",
    "    global example_ct_valid\n",
    "    global batch_ct_valid\n",
    "\n",
    "    #Validation Loop \n",
    "    #Intialize train_loss at the start of the epoch\n",
    "    running_valid_loss = 0\n",
    "\n",
    "    #put model in the evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input,targets in loader:\n",
    "\n",
    "            # move inputs and outputs to GPUs\n",
    "            input = input.to(device)\n",
    "            targets = targets.to(device)   \n",
    "\n",
    "            #Forward pass\n",
    "            output=model(input)\n",
    "            loss=loss_function(output,targets.float())\n",
    "\n",
    "            #count of images and batches \n",
    "            example_ct_valid += len(targets)\n",
    "            batch_ct_valid +=1\n",
    "\n",
    "            #Add valid loss of a batch\n",
    "            running_valid_loss +=loss.item()\n",
    "\n",
    "            #log batch loss and accuracy\n",
    "            if log_batch:\n",
    "                if ((batch_ct_valid + 1) % log_interval) == 0:\n",
    "                    wandb.log({f\"Valid Batch Loss :\": loss})\n",
    "\n",
    "            #Calculate mean valid loss for the whole dataset for particular epoch\n",
    "            valid_loss = running_valid_loss/len(loader)\n",
    "\n",
    "        return valid_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining the training loop\n",
    "\n",
    "def train_loop(train_loader,valid_loader, model,loss_function,optimizer, epochs,device, patience, early_stopping, file_model):\n",
    "     '''\n",
    "  model: specify your model for training\n",
    "  criterion: loss function \n",
    "  optimizer: optimizer like SGD , ADAM etc.\n",
    "  train loader: function to carete batches for training data\n",
    "  valid loader : function to create batches for valid data set\n",
    "  file_model : specify file name for saving your model. This way we can upload the model weights from file. We will not to run model again.\n",
    "  \n",
    "\n",
    "  '''\n",
    "     #Create a list to store the train and valid loss at each epoch\n",
    "     train_loss_history = []\n",
    "     valid_loss_history=[]\n",
    "\n",
    "     delta=0\n",
    "     best_score=None\n",
    "     valid_loss_min =np.Inf\n",
    "     counter_early_stop=0\n",
    "     early_stop=False\n",
    "\n",
    "\n",
    "     #Iterate for a given number of epochs \n",
    "     for epoch in range(epochs):\n",
    "          t0=datetime.now()\n",
    "\n",
    "          #Get train loss and accuracy for one epoch\n",
    "\n",
    "          train_loss= train(train_loader,model,optimizer, loss_function,wandb.config.LOG_BATCH,wandb.config.LOG_INTERVAL,wandb.config.GRAD_CLIPPING,wandb.config.MAX_NORM)\n",
    "\n",
    "          valid_loss= valid(valid_loader, model, optimizer, loss_function,wandb.config.LOG_BATCH,wandb.config.LOG_INTERVAL)\n",
    "\n",
    "          dt=datetime.now()-t0\n",
    "\n",
    "          #Save history of losses and accuracy\n",
    "          train_loss_history.append(train_loss)\n",
    "\n",
    "          valid_loss_history.append(valid_loss)\n",
    "\n",
    "          if early_stopping:\n",
    "               score= -valid_loss\n",
    "               if best_score is None:\n",
    "                    best_score=score\n",
    "                    print(f'Validation loss has decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Saving Model..')\n",
    "                    torch.save(model.state_dict(),file_model)\n",
    "                    valid_loss_min=valid_loss\n",
    "\n",
    "               elif score<best_score+delta:\n",
    "                     counter_early_stop+=1\n",
    "                     print(f\"Early Stopping counter: {counter_early_stop} out of {patience}\")\n",
    "                     if counter_early_stop > patience:\n",
    "                          early_stop=True\n",
    "\n",
    "               else:\n",
    "                    best_score=score\n",
    "                    print(f\"Validationn loss had decreased ({valid_loss_min:.6f}) --> {valid_loss:.6f}). Saving model.. \")\n",
    "                    torch.save(model.state_dict(),file_model)\n",
    "                    counter_early_stop=0\n",
    "                    valid_loss_min=valid_loss\n",
    "               \n",
    "               if early_stop:\n",
    "                    print(\"Early Stopping\")\n",
    "                    break\n",
    "          else:\n",
    "               score = -valid_loss\n",
    "               if best_score is None:\n",
    "                    best_score=score\n",
    "                    print(f\"Validation loss has decreased ({valid_loss_min:.6f}) --> {valid_loss:.6f}). Saving Model..\")\n",
    "                    torch.save(model.state_dict(),file_model)\n",
    "                    valid_loss_min=valid_loss\n",
    "\n",
    "               elif score<best_score+delta:\n",
    "                    print(f\"Validation score has not decreased ({valid_loss_min:.6f} --> {valid_loss:.6f}). Not Saving Model..\")\n",
    "\n",
    "               else:\n",
    "                    best_score = score\n",
    "                    print(f\"Validation loss has decreased ({valid_loss_min:.6f}--> {valid_loss:.6f}). Saving Model\")\n",
    "                    torch.save(model.state_dict(),file_model)\n",
    "                    valid_loss_min=valid_loss\n",
    "\n",
    "          #Log the train and valid loss to W&B\n",
    "          wandb.log({f\"Train epoch loss:\":train_loss, f\"Valid epoch Loss :\":valid_loss})\n",
    "\n",
    "          #Print the train loss and accuracy for given number of epochs, batch size and number of samples\n",
    "          print(f\"Epochs : {epoch+1} / {epochs}\")\n",
    "          print(f\"Time to complete {epoch+1} is {dt}\")\n",
    "\n",
    "          print(f\"Train loss:  {train_loss: .4f}\")\n",
    "\n",
    "          print(f\"Valid lodd: {valid_loss : .4f}\")\n",
    "\n",
    "          print()\n",
    "\n",
    "          torch.cuda.empty_cache()\n",
    "      \n",
    "     return train_loss_history, valid_loss_history\n",
    "               \n",
    "\n",
    "                    \n",
    "               \n",
    "            \n",
    "               \n",
    "               \n",
    "\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Hyperparameters\n",
    "hyperparameters= SimpleNamespace(\n",
    "    INPUT_DIM = train_set.tensors[0].shape[1],\n",
    "    OUTPUT_DIM = 8,\n",
    "    HIDDEN_DIM1 = 512,\n",
    "    HIDDEN_DIM2 = 256,\n",
    "    NON_LINEARITY= F.relu,\n",
    "    EPOCHS = 40,\n",
    "    \n",
    "    BATCH_SIZE = 4,\n",
    "    LEARNING_RATE = 0.01,\n",
    "    DATASET=\"Multilabel\",\n",
    "    ARCHITECTUREe=\"IntentModellingV2\",\n",
    "    LOG_INTERVAL = 25,\n",
    "    LOG_BATCH = True,\n",
    "    FILE_MODEL = 'IntentModelV2.pt',\n",
    "    GRAD_CLIPPING = False,\n",
    "    MAX_NORM = 0,\n",
    "    MOMENTUM = 0,\n",
    "    PATIENCE = 5,\n",
    "    EARLY_STOPPING = True,\n",
    "    # SCHEDULER_FACTOR = 0,\n",
    "    # SCHEDULER_PATIENCE = 0,\n",
    "    WEIGHT_DECAY = 0\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "wandb version 0.15.8 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Github repos\\IntentModelling\\wandb\\run-20230816_100241-suaaj7ol</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/aswin1903/NLP/runs/suaaj7ol' target=\"_blank\">Intent Modelling V2</a></strong> to <a href='https://wandb.ai/aswin1903/NLP' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/aswin1903/NLP' target=\"_blank\">https://wandb.ai/aswin1903/NLP</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/aswin1903/NLP/runs/suaaj7ol' target=\"_blank\">https://wandb.ai/aswin1903/NLP/runs/suaaj7ol</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/aswin1903/NLP/runs/suaaj7ol?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x1a61f5cff50>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize new Project \n",
    "import random\n",
    "wandb.init(name=\"Intent Modelling V2\", project=\"NLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wandb.config=hyperparameters\n",
    "non_linearity=F.relu\n",
    "wandb.Config.NON_LINEARITY = non_linearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fix seed value \n",
    "SEED=1234\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic=True\n",
    "\n",
    "#DATA Loaders\n",
    "train_loader=torch.utils.data.DataLoader(train_set,batch_size=wandb.config.BATCH_SIZE,shuffle=True,num_workers=4)\n",
    "valid_loader=torch.utils.data.DataLoader(valid_set,batch_size=wandb.config.BATCH_SIZE,shuffle=True,num_workers=4)\n",
    "test_loader=torch.utils.data.DataLoader(test_Set,batch_size=wandb.config.BATCH_SIZE,shuffle=True,num_workers=4)\n",
    "\n",
    "#Cross entropy loss function\n",
    "loss_function= nn.BCEWithLogitsLoss()\n",
    "\n",
    "#use GPU\n",
    "device=torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "wandb.config.DEVICE=device\n",
    "\n",
    "#Model\n",
    "model=Model(wandb.config.INPUT_DIM, wandb.config.HIDDEN_DIM1, wandb.config.HIDDEN_DIM2, wandb.config.OUTPUT_DIM, wandb.config.NON_LINEARITY)\n",
    "\n",
    "model.to(wandb.config.DEVICE)\n",
    "\n",
    "def init_weights(m):\n",
    "    if type(m) == nn.Linear:\n",
    "        torch.nn.init.kaiming_normal_(m.weight)\n",
    "        torch.nn.init.zeros_(m.bias)\n",
    "\n",
    "#Apply initialization recursively to all modules\n",
    "model.apply(init_weights)\n",
    "\n",
    "#Initialize stochiastic gradient descent optimizer\n",
    "optimizer = torch.optim.Adam(model.parameters(),lr=wandb.config.LEARNING_RATE,weight_decay=wandb.config.WEIGHT_DECAY)\n",
    "\n",
    "wandb.config.OPTIMIZER = optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual loss: 0.6926751732826233\n",
      "Expected Theoretical loss: 0.6931471805599453\n"
     ]
    }
   ],
   "source": [
    "#Sanity Check \n",
    "for input_, targets in train_loader:\n",
    "  \n",
    "  # move inputs and outputs to GPUs\n",
    "  input_ = input_.to(device)\n",
    "  targets = targets.to(device)\n",
    "  model.eval()\n",
    "  # Forward pass\n",
    "  output = model(input_)\n",
    "  loss = loss_function(output, targets.float())\n",
    "  print(f'Actual loss: {loss}')\n",
    "  break\n",
    "\n",
    "print(f'Expected Theoretical loss: {np.log(2)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: logging graph, to disable use `wandb.watch(log_graph=False)`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<wandb.wandb_torch.TorchGraph at 0x1a61ed01650>]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Training model\n",
    "wandb.watch(model, log = 'all', log_freq=25, log_graph=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation loss has decreased (inf --> 0.241736). Saving Model..\n",
      "Epochs : 1 / 40\n",
      "Time to complete 1 is 0:00:21.571344\n",
      "Train loss:   0.3089\n",
      "Valid lodd:  0.2417\n",
      "\n",
      "Validationn loss had decreased (0.241736) --> 0.219807). Saving model.. \n",
      "Epochs : 2 / 40\n",
      "Time to complete 2 is 0:00:16.837475\n",
      "Train loss:   0.1576\n",
      "Valid lodd:  0.2198\n",
      "\n",
      "Early Stopping counter: 1 out of 5\n",
      "Epochs : 3 / 40\n",
      "Time to complete 3 is 0:00:13.981367\n",
      "Train loss:   0.0712\n",
      "Valid lodd:  0.2439\n",
      "\n",
      "Validationn loss had decreased (0.219807) --> 0.206728). Saving model.. \n",
      "Epochs : 4 / 40\n",
      "Time to complete 4 is 0:00:13.966977\n",
      "Train loss:   0.0345\n",
      "Valid lodd:  0.2067\n",
      "\n",
      "Early Stopping counter: 1 out of 5\n",
      "Epochs : 5 / 40\n",
      "Time to complete 5 is 0:00:13.716720\n",
      "Train loss:   0.0365\n",
      "Valid lodd:  0.2347\n",
      "\n",
      "Early Stopping counter: 2 out of 5\n",
      "Epochs : 6 / 40\n",
      "Time to complete 6 is 0:00:13.646295\n",
      "Train loss:   0.0230\n",
      "Valid lodd:  0.2633\n",
      "\n",
      "Early Stopping counter: 3 out of 5\n",
      "Epochs : 7 / 40\n",
      "Time to complete 7 is 0:00:16.362373\n",
      "Train loss:   0.0264\n",
      "Valid lodd:  0.3538\n",
      "\n",
      "Early Stopping counter: 4 out of 5\n",
      "Epochs : 8 / 40\n",
      "Time to complete 8 is 0:00:15.335888\n",
      "Train loss:   0.0353\n",
      "Valid lodd:  0.2838\n",
      "\n",
      "Early Stopping counter: 5 out of 5\n",
      "Epochs : 9 / 40\n",
      "Time to complete 9 is 0:00:13.943808\n",
      "Train loss:   0.0487\n",
      "Valid lodd:  0.3498\n",
      "\n",
      "Early Stopping counter: 6 out of 5\n",
      "Early Stopping\n"
     ]
    }
   ],
   "source": [
    "example_ct_train,batch_ct_train, example_ct_valid,batch_ct_valid = 0, 0, 0, 0\n",
    "\n",
    "train_loss_history, valid_loss_history = train_loop(train_loader, valid_loader, \n",
    "                                                                                          model,\n",
    "                                                                                          loss_function, \n",
    "                                                                                          optimizer, \n",
    "                                                                                          wandb.config.EPOCHS, \n",
    "                                                                                          wandb.config.DEVICE,\n",
    "                                                                                          wandb.config.PATIENCE, \n",
    "                                                                                          wandb.config.EARLY_STOPPING,\n",
    "                                                                                          wandb.config.FILE_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#LOSS PLOT\n",
    "# Plot the train loss and test loss per iteration\n",
    "import matplotlib.pyplot as plt \n",
    "fig = plt.figure(0)\n",
    "plt.plot(train_loss_history, label = 'train loss')\n",
    "plt.plot(valid_loss_history, label = 'valid loss')\n",
    "plt.legend()\n",
    "\n",
    "# Log the plot to W&B\n",
    "wandb.log({\"train-test loss per epoch\": wandb.Image(plt)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_nn = Model(wandb.config.INPUT_DIM, wandb.config.HIDDEN_DIM1, wandb.config.HIDDEN_DIM2, wandb.config.OUTPUT_DIM, non_linearity)\n",
    "model_nn.to(device)\n",
    "model_nn.load_state_dict(torch.load(wandb.config.FILE_MODEL))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(data_loader, model, device):\n",
    "    \"\"\" \n",
    "    Function to evaluate the performance of a given model on a dataset\n",
    "    Input: Data iterator, Model, Device (CPU or GPU)\n",
    "    Output: Predictions, Actual labels, Classification report, F1 score\n",
    "    \"\"\"\n",
    "    # Array to store predicted labels\n",
    "    predictions = torch.Tensor().to(device)\n",
    "\n",
    "    # Array to store actual labels\n",
    "    y_true = torch.Tensor().to(device)\n",
    "\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_, targets in data_loader:\n",
    "            input_ = input_.to(device)\n",
    "            targets = targets.to(device)\n",
    "\n",
    "            output = model(input_)\n",
    "            prediction = torch.sigmoid(output)\n",
    "            indices = (prediction >= 0.5).float()  # Threshold predictions\n",
    "\n",
    "            # Add the predicted labels to the array\n",
    "            predictions = torch.cat((predictions, indices))\n",
    "\n",
    "            # Add the actual labels to the array\n",
    "            y_true = torch.cat((y_true, targets))\n",
    "\n",
    "    # Convert tensors to numpy arrays\n",
    "    predictions = predictions.cpu().numpy()\n",
    "    y_true = y_true.cpu().numpy()\n",
    "\n",
    "    # Generate classification report\n",
    "    report = classification_report(y_true, predictions, target_names=[\"class1\", \"class2\", ...])\n",
    "\n",
    "    # Calculate F1 score\n",
    "    f1 = f1_score(y_true, predictions, average=\"weighted\")\n",
    "\n",
    "    return predictions, y_true, report, f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Function for Accuracy\n",
    "\n",
    "def get_acc_pred(data_loader, model,device):\n",
    "    \n",
    "  \"\"\" \n",
    "  Function to get predictions and accuracy for a given data using estimated model\n",
    "  Input: Data iterator, Final estimated weoights, bias\n",
    "  Output: Precditions and Accuracy for given dataset\n",
    "  \"\"\"\n",
    "\n",
    "  # Array to store predicted labels\n",
    "  predictions = torch.Tensor() # empty tensor\n",
    "  predictions = predictions.to(device) # move predictions to GPU\n",
    "\n",
    "  # Array to store actual labels\n",
    "  y = torch.Tensor() # empty tensor\n",
    "  y = y.to(device)\n",
    "\n",
    "  total=0\n",
    "  correct=0\n",
    "  # Iterate over batches from data iterator\n",
    "  with torch.no_grad():\n",
    "    for input_, targets in data_loader:\n",
    "      \n",
    "      # move inputs and outputs to GPUs\n",
    "      \n",
    "      input_ = input_.to(device)\n",
    "      targets = targets.to(device)\n",
    "      \n",
    "      # Calculated the predicted labels\n",
    "      output = model(input_)\n",
    "\n",
    "      # Choose the label with maximum probability\n",
    "      prediction = torch.sigmoid(output)\n",
    "      indices=prediction\n",
    "      indices[indices>0.5]=1\n",
    "      indices[indices<0.5]=0\n",
    "\n",
    "      # Add the predicted labels to the array\n",
    "      predictions = torch.cat((predictions, indices)) \n",
    "\n",
    "      # Add the actual labels to the array\n",
    "      y = torch.cat((y, targets))\n",
    "\n",
    "      predicted = np.round(prediction) #keep in mind that np.round() is a round to even function\n",
    "      total += targets.size(0)\n",
    "      #print(\"Target: \",targets.size(0))\n",
    "      #print(\"Predicted: \",predicted)\n",
    "      #print(\"Target: \", targets)\n",
    "      #calculate how many images were correctly classified\n",
    "      correct += (predicted == targets).sum().item()\n",
    "      #print(correct)\n",
    "  accuracy=100.0* (correct/total)\n",
    "  print(\"Accuracy: {}%\".format(accuracy))\n",
    "  # Check for complete dataset if actual and predicted labels are same or not\n",
    "  # Calculate accuracy\n",
    "  #acc = (predictions == y).float().mean()\n",
    "\n",
    "  # Return tuple containing predictions and accuracy\n",
    "  return predictions, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function for predictions\n",
    "def get_predictions(data_loader, model,device):\n",
    "    # Array to store predicted labels\n",
    "    predictions = torch.Tensor() # empty tensor\n",
    "    predictions = predictions.to(device) # move predictions to GPU\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for input_ in data_loader:\n",
    "        \n",
    "            # move inputs and outputs to GPUs\n",
    "        \n",
    "            input_ = input_.to(device)\n",
    "            #targets = targets.to(device)\n",
    "            \n",
    "            # Calculated the predicted labels\n",
    "            output = model(input_)\n",
    "\n",
    "            # Choose the label with maximum probability\n",
    "            prediction = torch.sigmoid(output)\n",
    "            indices=prediction\n",
    "            indices[indices>0.5]=1\n",
    "            indices[indices<0.5]=0\n",
    "\n",
    "            # Add the predicted labels to the array\n",
    "            predictions = torch.cat((predictions, indices)) \n",
    "        return predictions\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pred_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[52], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mWeighted F1 score: \u001b[39m\u001b[39m{:.2f}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(f1_score(y_true\u001b[39m=\u001b[39m y_train, y_pred\u001b[39m=\u001b[39m pred_train, average\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mweighted\u001b[39m\u001b[39m'\u001b[39m)))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pred_train' is not defined"
     ]
    }
   ],
   "source": [
    "print(\"Weighted F1 score: {:.2f}\".format(f1_score(y_true= y_train, y_pred= pred_train, average= 'weighted')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_loader=torch.utils.data.DataLoader(X_test_tensor,batch_size=wandb.config.BATCH_SIZE,shuffle=False,num_workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "result=get_predictions(pred_loader,model_nn,device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 1., 0., 1., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [1., 1., 0., 0., 1., 1., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [1., 0., 0., 0., 0., 1., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 1., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=mlb.inverse_transform(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['the customer service person was extremely helpful and courteous',\n",
       "       'monica was awesome   she was friendly and very knowledgeable   she gave my issue her conllete attention and her follow up was thorough',\n",
       "       'leonel did a great job trying to help me unfortunately he was unable to locate the model of fan i had to purchase replacement parts i understand the ceiling fan is 20 years old but how do you or none of your vendors have information on it when i_x0019_ve provided the model and item number disappointed my issue isn_x0019_t resolved',\n",
       "       'product was damaged during shipping nsd does not wait to open the box i have been dealing with this since i opened the box the evening it was delivered part can not be replaced so i need to return still waiting on nsd to schedule the pick up for the return i was told 3 5 business days after 6/29 they will contact me then call me the day before via email their contact phone number when you ask to talk to a representative disconnects and i only learned of this timing via email after i got a email saying they tried to contact me the email was the first contact with nsd and i was told by home depot i would be able to pick the day at this point i just want someone to pick this item up and provide a refund as soon as possible please contact me immediately 410 688 3504',\n",
       "       'iiyasah was excellent to deal with they provided me with what i needed without issue and were very professional',\n",
       "       'maribel was very helpful   the wait time before talking to her was long but not her issue',\n",
       "       'thanks for making it easy   wow',\n",
       "       'david was very professional and handled my issues with excellence',\n",
       "       'great job',\n",
       "       'i would like the ability to receive customer service via email instead of phone the wait time on the phone was long but the customer service itself was excellent alejandro did a great job',\n",
       "       'i made 2 calls and left messages with support person and after a more then a week i have not gotten a call back',\n",
       "       \"i ran into a ridiculous policy issue with hampton bay i purchased 2 light fixtures a while back and in the process of installing one i dropped and broke a shade globe because i no longer have the receipt i was told i couldn''t purchase a shade some nonsense about a warranty period etc this was n't a warranty   claim i just wanted to purchase a shade globe needless to say i 'm not very happy i 've purchased an enormous amount of stuff from hd over the years buy i 'll think twice about it from now on\",\n",
       "       'michelle was awesome to find the part i needed for my ceiling fan   order process was easy   thank you',\n",
       "       'i have an issue with the stanley door i bought on line the door knob and the deadbolt lock did not line up with the door jam after installation pedro offered a credit but i still have brand new door with holes that don_x0019_t match waiting for a response from danvers home depot to let me know what going to happen they also sold me the wrong extension kit',\n",
       "       'hector was extremely helpful and personable he definitely made the experience enjoyable',\n",
       "       'it would help if the home depot store in phoenix or answered their phone it took two trips to the store to schedule an installation after the materials arrived    everyone at home depot followed a process but no one seemed to be able to make anything happen   i will try lowes for my next custom order',\n",
       "       'i am still waiting to see what they will do about my damaged beverage fridge',\n",
       "       \"i ran into a ridiculous policy issue with hampton bay i purchased 2 light fixtures a while back and in the process of installing one i dropped and broke a shade globe because i no longer have the receipt i was told i couldn''t purchase a shade some nonsense about a warranty period etc this was n't a warranty   claim i just wanted to purchase a shade globe needless to say i 'm not very happy i 've purchased an enormous amount of stuff from hd over the years buy i 'll think twice about it from now on\",\n",
       "       'bob put the zing in amazing true american',\n",
       "       'detailed and helpful',\n",
       "       'ricardo and hugo were very good about getting things going and keeping me updated my only discontent is i still don_x0019_t have the part',\n",
       "       'javier did an amazing job',\n",
       "       'no one cares after spending over $ 3000 on decking and railings i had to remove the pieces myself from the racks it took over an hour and a half but was told it would be a long time for them to do it not very helpful'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "t=pd.DataFrame()\n",
    "t[\"pred\"]=y\n",
    "t[\"comments\"]=X_test.values\n",
    "t[\"actual_value\"]=mlb.inverse_transform(torch.tensor(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_colwidth', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "t.to_csv(\"IntentSample.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
